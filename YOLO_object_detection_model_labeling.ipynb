{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3853b35e-85b3-4061-85ee-a3922d5aecc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\1.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 45.0ms\n",
      "Speed: 6.7ms preprocess, 45.0ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "1.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\10.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 42.7ms\n",
      "Speed: 6.1ms preprocess, 42.7ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "10.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\11.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 42.7ms\n",
      "Speed: 6.0ms preprocess, 42.7ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "11.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\12.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 37.8ms\n",
      "Speed: 5.0ms preprocess, 37.8ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "12.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\13.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 44.8ms\n",
      "Speed: 6.0ms preprocess, 44.8ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "13.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\14.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 41.7ms\n",
      "Speed: 8.0ms preprocess, 41.7ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "14.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\15.jpg: 288x640 1 inverter, 1 warranty, 1 acer, 37.7ms\n",
      "Speed: 6.0ms preprocess, 37.7ms inference, 6.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "15.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\16.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 37.0ms\n",
      "Speed: 6.0ms preprocess, 37.0ms inference, 5.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "16.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\17.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 36.0ms\n",
      "Speed: 6.0ms preprocess, 36.0ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "17.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\18.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 39.0ms\n",
      "Speed: 6.0ms preprocess, 39.0ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "18.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\19.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 40.0ms\n",
      "Speed: 6.7ms preprocess, 40.0ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "19.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\2.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 37.1ms\n",
      "Speed: 6.6ms preprocess, 37.1ms inference, 5.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "2.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\20.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 38.7ms\n",
      "Speed: 6.1ms preprocess, 38.7ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "20.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\3.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 35.7ms\n",
      "Speed: 7.1ms preprocess, 35.7ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "3.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\4.jpg: 288x640 1 warranty, 1 acer, 37.8ms\n",
      "Speed: 6.0ms preprocess, 37.8ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "4.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\5.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 38.1ms\n",
      "Speed: 6.0ms preprocess, 38.1ms inference, 6.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "5.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\6.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 36.0ms\n",
      "Speed: 6.0ms preprocess, 36.0ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "6.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\7.jpg: 288x640 1 inverter, 1 star_rating, 1 warranty, 1 acer, 34.0ms\n",
      "Speed: 6.0ms preprocess, 34.0ms inference, 7.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "7.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\8.jpg: 288x640 1 warranty, 1 acer, 37.0ms\n",
      "Speed: 6.7ms preprocess, 37.0ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "8.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n",
      "\n",
      "image 1/1 D:\\ORAMA\\29_5_24_Amber\\acer\\test\\images\\9.jpg: 288x640 1 inverter, 1 warranty, 1 acer, 36.8ms\n",
      "Speed: 6.0ms preprocess, 36.8ms inference, 4.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "9.jpg saved in D:\\ORAMA\\29_5_24_Amber\\acer\\test\\testing\\experiment_8\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "random.seed(101)\n",
    "\n",
    "# Defining colors for classes later used for object detection trackers\n",
    "def classes_color(classes: dict):\n",
    "    color_dict = {} # Dictionary for storing classes with their corresponding RGB values\n",
    "\n",
    "    for i in range(len(classes)): # Looping through length of the classes\n",
    "        random.seed(i) # Setting up the seed for reproducibilty of RGB values\n",
    "        color_dict[i] = random.sample(range(256), 3) # Storing the RGB values\n",
    "        \n",
    "    return color_dict\n",
    "\n",
    "# object detection inference and auto labeling\n",
    "def object_detection(model_path: str, # Trained model path\n",
    "                     test_images_path: str, # Test images\n",
    "                     pred_save_path: str, # Save path for predictions\n",
    "                     auto_labeling= False): # Auto labeling command\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' # Device agnostic code\n",
    "\n",
    "    def get_model(model_path: str): # Getting the model\n",
    "        model = YOLO(model_path).to(device)\n",
    "        return model\n",
    "\n",
    "    model = get_model(model_path) \n",
    "\n",
    "    test_images_path = Path(test_images_path) # Test images path\n",
    "    test_images = list(test_images_path.glob('*.jpg')) # Putting '.jpg' files from the path in a list\n",
    "\n",
    "    # Setting up labels folder and path\n",
    "    labels_save_folder = \"labels\"\n",
    "    labels_save_dir = os.path.join(pred_save_path, labels_save_folder)\n",
    "\n",
    "    # Setting up Prediction save path\n",
    "    if not os.path.exists(pred_save_path):\n",
    "        os.mkdir(pred_save_path)\n",
    "\n",
    "    # Enumerating through test images and using attributes of the predictions\n",
    "    for i, image in enumerate(test_images):\n",
    "        \n",
    "        results = model(image) # Performing inference on an image\n",
    "        \n",
    "        img = results[0].orig_img # Getting the original image\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy().astype(np.int32) # Getting the bounding box co-ordinates ((x0, y0), (x1, y1)) format\n",
    "        labels = results[0].boxes.xywhn.cpu().numpy() # Getting the bounding box co-ordinates (x, y, w, h) format\n",
    "        classes = results[0].boxes.cls.cpu().numpy().astype(np.int32) # Classes represented by integers\n",
    "        classes_name = results[0].names # Classes dictionary\n",
    "        labels_color = classes_color(classes_name) # Unique color specific to classes\n",
    "        \n",
    "        image_filename = f'{test_images[i].stem}.jpg' # Defining the image name\n",
    "        txt_filename = f'{test_images[i].stem}.txt'\n",
    "\n",
    "        # Enumerating through boxes and classes to draw rectangles and put labels on the image\n",
    "        for i, (bbox, cls) in enumerate(zip(boxes, classes)):\n",
    "    \n",
    "            label = classes_name[cls] # Getting class name label\n",
    "            label_margin = 3 # Setting up a margin\n",
    "\n",
    "            # Getting the the text size given the parameters\n",
    "            label_size = cv.getTextSize(label, # label data\n",
    "                                        fontFace=cv.FONT_HERSHEY_SIMPLEX, # Font\n",
    "                                        fontScale=2.5, # Font size\n",
    "                                        thickness=5) # Font thickness\n",
    "\n",
    "            # Getting the label width and hight and setting up the margins\n",
    "            label_w, label_h = label_size[0]\n",
    "            label_w += 2*label_margin\n",
    "            label_h += 2*label_margin\n",
    "\n",
    "            # Drawing the rectangles using predicted co-ordinates\n",
    "            cv.rectangle(img, \n",
    "                         (bbox[0], bbox[1]), \n",
    "                         (bbox[2], bbox[3]), \n",
    "                         color= labels_color[cls], \n",
    "                         thickness=5)\n",
    "\n",
    "            # Drawing the label tag to put text upon\n",
    "            cv.rectangle(img, \n",
    "                         (bbox[0], bbox[1]), \n",
    "                         (bbox[0]+label_w, bbox[1]-label_h), \n",
    "                         color= labels_color[cls], \n",
    "                         thickness=-1)\n",
    "\n",
    "            # Putting the text upon the label tag\n",
    "            cv.putText(img, \n",
    "                       label, \n",
    "                       (bbox[0]+label_margin, bbox[1]-label_margin), \n",
    "                       fontFace=cv.FONT_HERSHEY_SIMPLEX, \n",
    "                       color=(255, 255, 255), \n",
    "                       fontScale= 2.5, \n",
    "                       thickness=8)\n",
    "\n",
    "            # Defining the function of autolabeling \n",
    "            if auto_labeling is True:\n",
    "                \n",
    "                if not os.path.exists(labels_save_dir): # Creating the directory for saving labels\n",
    "                    os.mkdir(labels_save_dir)\n",
    "    \n",
    "                txt_file_path = os.path.join(labels_save_dir, txt_filename)\n",
    "                \n",
    "                # Creating a text file and writing the data in it\n",
    "                with open(txt_file_path, 'a') as f:\n",
    "                    f.write(f\"{cls} {labels[i][0]} {labels[i][1]} {labels[i][2]} {labels[i][3]}\\n\")\n",
    "                f.close()\n",
    "        \n",
    "                print(f'Co-ordinates for {cls} is wriiten in {txt_filename} and saved in {labels_save_dir}')\n",
    "\n",
    "        # Saving the image in the designated path\n",
    "        cv.imwrite(os.path.join(pred_save_path, image_filename), img)\n",
    "        print(f'{image_filename} saved in {pred_save_path}')\n",
    "\n",
    "    if auto_labeling is True:\n",
    "        # Defining the 'classes.txt' file\n",
    "        class_filename = 'classes.txt'\n",
    "        class_file_path = os.path.join(labels_save_dir, class_filename)\n",
    "    \n",
    "        # writing the classes data in the txt file\n",
    "        for cls in classes_name:\n",
    "            with open(class_file_path, 'a') as f:\n",
    "                f.write(f'{classes_name[cls]}\\n')\n",
    "            f.close()\n",
    "        \n",
    "        print(f'\\n{class_filename} has been saved in {labels_save_dir}')\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033e592-0bc9-4b13-a826-d1516fc04b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
